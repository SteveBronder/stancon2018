---
title: "GPU Optimized Math Routines in the Stan Math Library"
author: |
  | Rok &#268;e&#353;novar, Davor Sluga, Jure Dem&#353;ar, Steve Bronder, Erik &#352;trumbelj
date: "Jul 9, 2018"
output:
  pdf_document: default
  html_document: default
bibliography: report.bib
---


```{r include = FALSE}
# wd
setwd("D:/Work/bitbucket/stancon2018")

# includes
library(ggplot2)
library(plyr)
library(rstan)
library(cowplot)
library(reshape)
```

# Introduction

The Stan library's Hamilton Monte Carlo sampler (NUTS) typically explores the target distribution more efficiently than alternative MCMC methods and requires fewer iterations. However, it requires the computation of the gradient and is computationally more expensive per iteration. The makes it an excellent candidate for GPU optimization.

Our motivating example were Gaussian Process (GP) models, where the computation is dominated by the inversion of the covariance matrix of the size of the data, which is typically done through Cholesky decomposition. We implemented GPU optimizations for the Cholesky decomposition and its derivative in the Stan Math library [@stanmath2015]. This is the first known open source GPU implementation of the Cholesky decomposition in an MCMC setting. Furthermore, the GPU kernels use OpenCL and are not restricted to a particular GPU vendor. While results show that GPU optimizations are not optimal for small $n \times m$ matrices, large matrices can see speedups of 7.8x while retaining precision. 

# GPU implementation

<!--
Currently, we aim at speeding up the biggest computational bottlenecks on the GPU, while the remaining (non-parallelized) Stan code is executed on the CPU. Therefore, we move the data to and from the GPU for each GPU-parallelized function. Removing this often unnecessary data transfer to and from the GPU is one of the main priorities of  future work.
-->
One of the most significant linear algebra bottlenecks in GP (and many other statistical models) is matrix inversion. In particular, the inversion of a positive semi-definite covariance matrix, which is typically done through Cholesky decomposition. This requires the computation of the decomposition, its derivative, and the derivative of solving the linear system $Ax = B$. To reduce these bottlenecks, we implemented GPU optimizations of the following Stan Math library methods:

\begin{enumerate}
\item	matrix transpose,
\item	multiplication of matrices with a diagonal and scalar,
\item	subtraction of matrices,
\item	copying submatrices,
\item	matrix multiplication,
\item	lower triangular matrix inverse,
\item	Cholesky decomposition,
\item first derivative of Cholesky decomposition.
\end{enumerate}

The execution times of methods (1-4) are negligible and thus our GPU implementations of these methods are simple and naive. For instance, in the multiplication of a $m \times n$ matrix with a scalar we create $m \times n$ threads, where each thread is assigned a single multiplication. These implementations are necessary to perform methods (6-8) on the GPU.

Stan's GPU matrix multiplication routines are based on the the routines in cuBLAS [@CUBLAS] and clBLAST. The matrix multiplication routines are optimized through two standard methods: assigning additional work to threads in large matrix multiplications and the use of tiling in local memory. Specific cases allow for specific optimization. For example, $A \times A^T$. Because the result is symmetric, the routine will reduce the number of multiplications by one half. 

The GPU implementations and optimizations of the lower triangular matrix inverse and the Cholesky decomposition are improvements on our previous work [@Cesnovar2017]. Details of these implementations are available in the following sections. The first derivative of the Cholesky decomposition is implemented using methods (1-7).

The OpenCL [@StoneOpenCL2010] context which manages the devices, platforms, memory, and kernels sits in \texttt{opencl\_context\_base::getInstance()} and is implemented in the Math library as a singleton. Developers can access the context through a friend adapter class called \texttt{opencl\_context} which provides a simple wrapper API for accessing the base context.

## Inverting a lower triangular matrix

The most widely used CPU algorithms for inverting a lower triangular matrix are not suitable for many-core architectures. Figure \ref{fig:blockInverse} gives a graphical illustration of the solution proposed in [@Mahfoudhi2012] that replaces most of the sequential code with matrix multiplications which are more suited for many-core systems.

The input matrix is split into blocks\footnote{The optimal number of blocks depends on the input matrix size and the GPU used. Thread blocks and warps will be in groupings of powers of two, so the optimal block size is recommended to be a power of two such as 32x32} as shown in Figure \ref{fig:blockInverse}. The first step is to calculate the matrix inversion of the smaller matrices $A1$ and $A2$. These inverses are done using the basic sequential algorithms, with small amounts of parallelism. The final step is the calculation of $C3 = -C2 \times A3 \times C1$.

![\label{fig:blockInverse}Blocked version of the lower triangualar matrix inverse.](_Figures/blockInverse.pdf)

## Cholesky decompostion

The GPU implementation of the Cholesky Decomposition comes from the blocked algorithm proposed in [@LouterNool1992]. Similar to the application of the lower triangular matrix inverse, the input matrix is split into blocks, as shown in Figure \ref{fig:blockCholesky}. A basic algorithm is first used to calculate the Cholesky Decomposition of $A_{11}$ and then the calculation of the inverse of $L_{11}^T$. Calculations for $L_{21}$ and $L_{22}$ proceeds as follows:

$$L_{21} = A_{21} (L_{11}^T)^{(-1)}$$

$$L_{22} = A_{22} - L_{21} (L_{21})^T$$

For larger matrices $(n > 1000)$, the algorithm is executed in 2 levels. For example, when $n = 2000$, the size of the block $A_{11}$ is $m = 400$. Because the sequential algorithm would be slow for a large $A_{11}$ block, the routine is run recursively on $A_{11}$ until $m$ reaches a reasonable size. 

![\label{fig:blockCholesky}Blocked version of the Cholesky decomposition.](_Figures/blockCholesky.pdf)

The implementation of the derivative of the Cholesky decomposition comes from the blocking method presented in [@Murray2016]. This algorithm is cache-friendly and uses GPU-suitable matrix operations. Similar to the inversion and Cholesky Decomposition, the input matrix is split into smaller blocks on which the algorithm performs various matrix operations: transpose, multiplication, lower triangular matrix inversion and subtraction. For details on the algorithm, refer to [@Murray2016].

Users can access the Cholesky GPU routines by calling \texttt{cholesky\_decompose\_gpu()} and \texttt{multi\_normal\_cholesky\_gpu()} in the stan language. In the latter, only the derivative of solving $Ax=b$ is run on the GPU. In the future, all GPU methods will be implemented in the same way so that users can make their code access the GPU routines by calling \texttt{<func\_name>\_gpu()}.

# Example: GP regression

Models that use large covariance matrices benefit from the Cholesky GPU routines. The example below uses 1D GP regression with hyperpriors from the case study [@Betancourt2017] (see the Appendix).

This example uses a toy dataset based on a simple, functional relationship between $x$ and $y$ with added Gaussian noise:

$$x_i \sim_{\text{iid}} U(-10,10)$$
$$y_i | x_i \sim_{\text{iid}} N \left( f(x), \frac{1}{10} \right), i = 1..n,$$
where $f(x) = \beta(x + x^2 - x^3 + 100 \sin 2x - \alpha)$. Parameters $\beta$ and $\alpha$ were set so that $E[f] = 0$ and $Var[f] = 1$. Figure \ref{fig:GP_fit} shows that there is no practical difference between GPU and CPU fits (however, the solutions are not identical).

```{r echo = FALSE, fig.cap="\\label{fig:GP_fit}Comparison of CPU and GPU fits.", fig.width = 12, fig.height = 6}

# load  results ----
stan_files <- list.files(
  path = "./_Results/",
  pattern = "GP", full.names = T
)

for (fn in stan_files) {
  summary <- readRDS(fn)
  
  # take one fit on largest N ----
  if (summary$N == 1024 && summary$iteration == 1)
  {

    if (summary$GPU)
      gpu_predict <- data.frame(x = summary$x,
                                y = summary$y,
                                x_predict = summary$x_predict,
                                y_predict = summary$y_predict,
                                GPU = TRUE)
    else
      cpu_predict <- data.frame(x = summary$x,
                                y = summary$y,
                                x_predict = summary$x_predict,
                                y_predict = summary$y_predict,
                                GPU = FALSE)
  }
}

df <- rbind(gpu_predict, cpu_predict)

ggplot() +
  geom_point(data = gpu_predict, aes(x = x, y = y), alpha = 0.1, shape = 16) +
  geom_line(data = df, aes(x = x_predict, y = y_predict, colour = GPU), size = 1) +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank()) +
  scale_colour_manual(values = c("#fc8d59", "#91bfdb"), labels = c("CPU", "GPU"))

```

We ran the model for different input sizes $n$ with and without GPU support. In both cases NUTS was used to sample from the posterior and all the settings were the same. Therefore, the only difference between the CPU and GPU experiments was that the latter peformed some Math routines on the GPU. We used a desktop computer with an Intel Core i7-4790 CPU running at $3.6 GHz$ and a Nvidia GTX1070 GPU.

Timing results are shown in Figure \ref{fig:GP_results} with measured times include sampling and warmup iterations, but not model compilation time. Due to unnecessary data transfers, the GPU implementation is not faster than the CPU version for smaller input sizes ($n < 750$). For larger $n$, the data transfer becomes negligible, and we can observe a speedup of $~7.8$ for $n = 5120$. Speedup measurements for larger $n$ were infeasible due to large CPU computation times. 

```{r echo = FALSE, fig.cap="\\label{fig:GP_results}Visualizations of speedup when using the GPU approach compared to the default CPU implementation. For simulations ran with the default CPU implementation executed for only simulations up to $n = 2048$, times reported for larger n are estimated from measurements for smaller n.", fig.width = 12, fig.height = 6, fig.pos = "H"}

# load  results ----
stan_files <- list.files(
	path = "./_Results/",
	pattern = "GP", full.names = T
)

# load data ----
stan_summary <- NULL
stan_summary_log <- NULL

for (fn in stan_files) {
	summary <- readRDS(fn)
	
	stan_summary <- rbind(stan_summary, data.frame(N = summary$N,
																								 time = summary$time,
																								 GPU = summary$GPU))
	
	stan_summary_log <- rbind(stan_summary_log, data.frame(N = log(summary$N, 10),
																												 time = log(summary$time, 10),
																												 GPU = summary$GPU))
}

# interpolate CPU ----
df_cpu <- stan_summary_log[stan_summary_log$GPU == FALSE, ]
lm_fit <- lm(time ~ poly(N,2), data = df_cpu)

N <- c(log(3072, 10), log(4096, 10), log(5120, 10))
df_interpolate <- data.frame(N = N,
                             time = predict(lm_fit, newdata = data.frame(N = N)),
                             GPU = FALSE)

stan_summary_log <- rbind(stan_summary_log, df_interpolate)

df_interpolate$N = c(3072, 4096, 5120)
df_interpolate$time = 10^df_interpolate$time
stan_summary <- rbind(stan_summary, df_interpolate)

# get mean and CI ----
stan_mean <- ddply(.data = stan_summary,
									 .variables = ~ N + GPU,
									 .fun = summarize,
									 time_mean = mean(time),
									 low_time = quantile(time, 0.025, na.rm = TRUE),
									 high_time = quantile(time, 0.975, na.rm = TRUE))

stan_mean_log <- ddply(.data = stan_summary_log,
											 .variables = ~ N + GPU,
											 .fun = summarize,
											 time_mean = mean(time),
											 low_time = quantile(time, 0.025, na.rm = TRUE),
											 high_time = quantile(time, 0.975, na.rm = TRUE))

# plot ----
left_plot <- ggplot(data = stan_mean,
										aes(x = N, y = time_mean, group = GPU, colour = GPU)) +
	geom_point(data = stan_summary,
						 aes(x = N, y = time, colour = GPU),
						 size = 4, alpha = 0.3, shape = 16) +
	geom_line(size = 1) +
	ylab("Time [s]") +
	xlab("N") +
	theme_minimal() +
	theme(legend.position = "bottom", legend.title = element_blank()) +
	scale_colour_manual(values = c("#fc8d59", "#91bfdb"), labels = c("CPU", "GPU"))

right_plot <- ggplot(data = stan_mean_log, 
										 aes(x = N, y = time_mean, group = GPU, colour = GPU)) +
	geom_point(data = stan_summary_log, aes(x = N, y = time, colour = GPU),
						 size = 4, alpha = 0.3, shape = 16) +
	geom_line(size = 1) +
	ylab(expression(log[10](time)~"[s]")) +
	xlab(expression(log[10](N))) +
	theme_minimal() +
	theme(legend.position = "bottom", legend.title = element_blank()) +
	scale_colour_manual(values = c("#fc8d59", "#91bfdb"), labels = c("CPU", "GPU"))

plot_grid(left_plot, right_plot, ncol = 2, nrow = 1, scale = 0.9)
```

# Conclusion

Our GPU optimized methods in Stan result in practically meaningful speedups. Parallelizing the Cholesky, its derivative and the derivative of solving $Ax=B$  provides $7.8$-fold speedups or more for programs which depend on large covariance matrices. As this project continues, we plan to (a) removing unnecessary data transfers to and from the GPU, which is currently our most significant bottleneck, (b) allow \texttt{rstan} [@rstan2018] access to the GPU methods, and (c) add GPU-optimized implementations for other computational building blocks, such as other matrix methods, density computation, and random variate generation.

\newpage
# Appendix

## Reproducing the simulations

Our simulations take several days to complete, so the results in this R Markdown file are not computed each time the manuscript is compiled. In order to achieve a reasonable compilation time of the R Markdown file, we decided to use precomputed results.

To recompute the results, you have to use the GP.R script from the _Simulations folder. Newly calculated results will be saved into the _Simulations/_Output/GP folder. To replace precomputed results with the new ones you have to delete all files from the _Results folder and replace them with files from _Simulations/_Output/GP folder.

Unforuntately, using the GPU routines in Stan Math Library is not straightforward. To use these routines you must first install the appropriate version of the library and then recompile CmdStan. See \href{https://github.com/bstatcomp/math/wiki/OpenCL-GPU-support} for detailed instructions. Pay special attention to the section Integration with CmdStan. Once you succesfully compile GpuStan with GPU support you only have to change the working and CmdStan directories at the top of the GP.R script and you are ready to go! Currently, simulations can only be run on Windows.

## Stan model for Gaussian process regression

```
functions {
  vector gp_pred_rng(real[] x2,
                     vector y1, real[] x1,
                     real alpha, real rho, real sigma, real delta) {
    int N1 = rows(y1);
    int N2 = size(x2);
    vector[N2] f2;
    {
      matrix[N1, N1] K =   cov_exp_quad(x1, alpha, rho)
                         + diag_matrix(rep_vector(square(sigma), N1));
      matrix[N1, N1] L_K = cholesky_decompose(K);

      vector[N1] L_K_div_y1 = mdivide_left_tri_low(L_K, y1);
      vector[N1] K_div_y1 = mdivide_right_tri_low(L_K_div_y1', L_K)';
      matrix[N1, N2] k_x1_x2 = cov_exp_quad(x1, x2, alpha, rho);
      vector[N2] f2_mu = (k_x1_x2' * K_div_y1);
      matrix[N1, N2] v_pred = mdivide_left_tri_low(L_K, k_x1_x2);
      matrix[N2, N2] cov_f2 =   cov_exp_quad(x2, alpha, rho) - v_pred' * v_pred
                              + diag_matrix(rep_vector(delta, N2));
      f2 = multi_normal_rng(f2_mu, cov_f2);
    }
    return f2;
  }
}

data {
  int<lower=1> N;
  real x[N];
  vector[N] y;

  int<lower=1> N_predict;
  real x_predict[N_predict];
}

parameters {
  real<lower=0> rho;
  real<lower=0> alpha;
  real<lower=0> sigma;
}

model {
  matrix[N, N] cov =   cov_exp_quad(x, alpha, rho)
                     + diag_matrix(rep_vector(square(sigma), N));
  matrix[N, N] L_cov = cholesky_decompose(cov); // cholesky_decompose_gpu in GPU model

  // P[rho < 2.0] = 0.01
  // P[rho > 10] = 0.01
  rho ~ inv_gamma(8.91924, 34.5805);
  alpha ~ normal(0, 2);
  sigma ~ normal(0, 1);

  y ~ multi_normal_cholesky(rep_vector(0, N), L_cov);
}

generated quantities {
  vector[N_predict] f_predict = gp_pred_rng(x_predict, y, x, alpha, rho, sigma, 1e-10);
  vector[N_predict] y_predict;
  for (n in 1:N_predict)
    y_predict[n] = normal_rng(f_predict[n], sigma);
}

```
## Original Computing Environment

```{r}
sessionInfo()
```

\newpage
# References
